{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f239b9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Day 01: Exploring data with `pandas`\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/819/1*Dss7A8Z-M4x8LD9ccgw7pQ.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbd506",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "Today, we will make sure that everyone learns how they can use `pandas`, `matplotlib`, and `seaborn`.\n",
    "\n",
    "After working through these ideas, you should be able to:\n",
    "1. know where to find the documentation for `pandas`, `matplotlib`, and `seaborn`\n",
    "2. load a dataset with `pandas` and explore it\n",
    "3. visualize a dataset with `matplotlib` and `seaborn`\n",
    "4. do some basic data analysis\n",
    "\n",
    "## Notebook instructions\n",
    "\n",
    "We will work through the notebook making sure to write all necessary code and answer any questions. We will start together with the most commonly performed tasks. Then you will work on the analyses, posed as research questions, in groups.\n",
    "\n",
    "## Outline:\n",
    "\n",
    "1. [Stellar Classification Dataset - SDSS17](#dataset)\n",
    "2. [Loading and exploring a dataset](#loading)\n",
    "3. [Visualizing your data](#visualizing)\n",
    "4. [Data analysis](#analysis)\n",
    "\n",
    "### Useful imports (make sure to execute this cell!)\n",
    "Let's get a few of our imports out of the way. If you find others you need to add, consider coming back and putting them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406675fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports for this notebook\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('ticks') # setting style\n",
    "sns.set_context('talk') # setting context\n",
    "sns.set_palette('colorblind') # setting palette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516dcca",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "We will be using the following libraries to get started:\n",
    "\n",
    "* `numpy` for numerical operations. \n",
    "> The `numpy` library is a fundamental package for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. You can find the documentation [here](https://numpy.org/doc/stable/).\n",
    "* `pandas` for data manipulation. \n",
    "> The `pandas` library is a powerful tool for data analysis and manipulation in Python. It provides data structures like DataFrames and Series, which make it easy to work with structured data. It is quickly becoming the standard for data analysis in Python. You can find the documentation [here](https://pandas.pydata.org/docs/).\n",
    "* `matplotlib` for data visualization. \n",
    "> The `matplotlib` library is a widely used library for creating static, animated, and interactive visualizations in Python. It provides a flexible framework for creating a wide range of plots and charts. You can find the documentation [here](https://matplotlib.org/stable/contents.html).\n",
    "* `seaborn` for statistical data visualization. \n",
    "> The `seaborn` library is built on top of `matplotlib` and provides a high-level interface for drawing attractive and informative statistical graphics. It simplifies the process of creating complex visualizations. You can find the documentation [here](https://seaborn.pydata.org/).\n",
    "\n",
    "**NOTE**: You should read through documentation for these libraries as you go along. The documentation is a great resource for learning how to use these libraries effectively. And the documentation is written the same way for almost all Python libraries, so it is a good skill to develop as you learn to use Python for science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b8a3e",
   "metadata": {},
   "source": [
    "----\n",
    "<a id=\"dataset\"></a>\n",
    "## 1. Stellar Classification Dataset - SDSS17\n",
    "\n",
    "The [Stellar Classification Dataset](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17) is a collection of observations of stars from the Sloan Digital Sky Survey (SDSS). The dataset contains various features of stars, such as their brightness, color, and spectral type, which can be used to classify them into different categories. The data set has 100,000 observations of starts, with 17 features and 1 class column. The features include:\n",
    "\n",
    "| Feature        | Description |\n",
    "|----------------|-------------|\n",
    "| obj_ID         | Object Identifier, the unique value that identifies the object in the image catalog used by the CAS |\n",
    "| alpha          | Right Ascension angle (at J2000 epoch) |\n",
    "| delta          | Declination angle (at J2000 epoch) |\n",
    "| u              | Ultraviolet filter in the photometric system |\n",
    "| g              | Green filter in the photometric system |\n",
    "| r              | Red filter in the photometric system |\n",
    "| i              | Near Infrared filter in the photometric system |\n",
    "| z              | Infrared filter in the photometric system |\n",
    "| run_ID         | Run Number used to identify the specific scan |\n",
    "| rereun_ID      | Rerun Number to specify how the image was processed |\n",
    "| cam_col        | Camera column to identify the scanline within the run |\n",
    "| field_ID       | Field number to identify each field |\n",
    "| spec_obj_ID    | Unique ID used for optical spectroscopic objects (this means that 2 different observations with the same spec_obj_ID must share the output class) |\n",
    "| redshift       | Redshift value based on the increase in wavelength |\n",
    "| plate          | Plate ID, identifies each plate in SDSS |\n",
    "| MJD            | Modified Julian Date, used to indicate when a given piece of SDSS data was taken |\n",
    "| fiber_ID       | Fiber ID that identifies the fiber that pointed the light at the focal plane in each observation |\n",
    "\n",
    "And the class column is:\n",
    "\n",
    "| Feature        | Description |\n",
    "|----------------|-------------|\n",
    "| class | object class (galaxy, star or quasar object) |\n",
    "\n",
    "Some of the features are values representing the brightness of the star in different filters, while others are positional coordinates in the sky. The class column indicates whether the object is a galaxy, star, or quasar. \n",
    "\n",
    "\n",
    "For this exercise, we will use the Stellar Classification Dataset to explore how to load and visualize data using `pandas`, `matplotlib`, and `seaborn`. Later we will use this dataset for some classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3523178",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"loading\"></a>\n",
    "## 2. Loading and exploring a dataset\n",
    "\n",
    "The goal is typically to read some sort of preexisting data **into** a DataFrame so we can work with it. \n",
    "\n",
    "Pandas is pretty flexible about reading in data and can read in a [variety of formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html). However, it sometimes needs a little help. We are going to read in a CSV file, which is a common format for data. \n",
    "\n",
    "The Stellar Classification dataset is one that has a particularly nice set of features and is of a manageable size such that it can be used as a good dataset for learning new data analysis techiques or testing out code. This allows one to focus on the code and data science methods without getting too caught up in wrangling the data. However, **data wrangling** is an authentic part of doing any sort of meaningful data analysis as data more often messier than not. \n",
    "\n",
    "Although you will be working with this dataset today, you may still have to do a bit of wrangling along the way.\n",
    "\n",
    "### 2.1 Reading in the data\n",
    "\n",
    "Download the data set from [Kaggle](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17) and save it in the same directory as this notebook, or you can use the following code to load it if you cloned the repository.\n",
    "\n",
    "**NOTE:** We need to check this data for missing values or other issues before we can use it.\n",
    "\n",
    "### âœ… Tasks: \n",
    "\n",
    "* Using `read_csv()` to load the data\n",
    "* Using `head()` to look at the first few rows\n",
    "\n",
    "**Note:** For this data set, `read_csv()` will automatically detect the delimiter as a comma, so we don't need to specify it. If you were reading in a file with a different delimiter, you would need to specify it using the `sep` parameter. Moreover, if the data had headers that were not the first row, you would need to specify the `header` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95585e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705f54b",
   "metadata": {},
   "source": [
    "### 2.2 Checking the data\n",
    "\n",
    "One of the first things we want to do is check the data for missing values or other issues. The `pandas` library provides several methods to help us with this. We will start by using `info()`, which provides a concise summary of the DataFrame, including the number of non-null values in each column and the data types.\n",
    "\n",
    "This is a good first step to understand the structure of the data and identify any potential issues, such as missing values or incorrect data types. Moreover, it will tell you how your data was imported, and if there are any columns that were not imported correctly.\n",
    "\n",
    "### âœ… Tasks: \n",
    "\n",
    "* Using `info()` to check the data types and missing values\n",
    "\n",
    "**What do you notice about the data? Are there any issue with the import?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9afab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6a288",
   "metadata": {},
   "source": [
    "Next, we will use `describe()` to get a summary of the data. This will give us some basic statistics about the numerical columns in the DataFrame, such as the mean, standard deviation, minimum, and maximum values. This is useful for understanding the distribution of the data and identifying any potential outliers.\n",
    "\n",
    "Researchers sometimes use aberrant values to identify potential issues with the data, such as errors in data entry or measurement. Sometimes, these values are read in as `NaN` (not a number) or `inf` (infinity), which can cause issues with analysis. But, other times, the researcher might force a particular value to be a certain number, such as 0 or 99, to indicate that the value is missing or not applicable.\n",
    "\n",
    "### âœ… Tasks: \n",
    "* Using `describe()` to get a summary of the data\n",
    "\n",
    "**What do you notice about the data? Are there any issue with starting the analysis?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed2bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c18d8",
   "metadata": {},
   "source": [
    "### 2.3 Slicing the data\n",
    "\n",
    "You likely noticed there were some problematic values in the data; some of the photometric values are negative, which is not possible. We will need to remove these rows from the DataFrame before we can do any analysis. However, we can also use this as an opportunity to practice slicing the DataFrame. So we will also reduce the DataFrame to only the columns we are interested in.\n",
    "\n",
    "Slicing a DataFrame is a common operation in `pandas` and allows you to select specific rows and columns based on certain conditions. You can use boolean indexing to filter the DataFrame based on conditions, such as selecting rows where a certain column is greater than a certain value. Here's some common examples of slicing a DataFrame:\n",
    "\n",
    "```python\n",
    "# Select all rows where the 'u' column is greater than 0\n",
    "df_u_positive = df[df['u'] > 0]\n",
    "# Select specific columns\n",
    "df_selected_columns = df[['obj_ID', 'class', 'u', 'g', 'r', 'i', 'z']]\n",
    "# Select rows where the 'class' column is 'star'\n",
    "df_stars = df[df['class'] == 'star']\n",
    "```\n",
    "\n",
    "### âœ… Tasks:\n",
    "\n",
    "* Reduce the DataFrame to only the columns we are interested in (`obj_ID`, `class`, `u`, `g`, `r`, `i`, `z`, and `redshift`) -  that is the object ID, class, and the photometric values in the different filters, as well as the redshift value.\n",
    "* Remove rows where any of the photometric values are negative (i.e., `u`, `g`, `r`, `i`, `z`).\n",
    "* Store the result in a new DataFrame called `df_stellar`.\n",
    "* Use `describe()` to check the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6315d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563029af",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id=\"visualizing\"></a>\n",
    "## 3. Visualizing your data\n",
    "\n",
    "Now that we have a clean DataFrame, we can start visualizing the data. Visualization is an important part of data analysis, as it allows us to see patterns and relationships in the data that may not be immediately obvious from the raw data. There a many ways to visualize data in `pandas`, but we will focus on two libraries: `matplotlib` and `seaborn`. These are the most commonly used libraries for data visualization in Python, and they provide a wide range of plotting options.\n",
    "\n",
    "### 3.1 Using `matplotlib`\n",
    "`matplotlib` is a powerful library for creating static, animated, and interactive visualizations in Python. It provides a flexible framework for creating a wide range of plots and charts. The most common way to use `matplotlib` is to create a figure and then add one or more axes to the figure. You can then plot data on the axes using various plotting functions. \n",
    "\n",
    "Here's a simple example of how to create a scatter plot using `matplotlib` for a DataFrame `df` with columns `x` and `y`:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "# Plot data on the axes\n",
    "ax.plot(df['x'], df['y'], 'o')\n",
    "# Set the x and y axis labels\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "# Set the title of the plot\n",
    "ax.set_title('x vs y')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### âœ… Tasks:\n",
    "* Create a scatter plot of `u` vs `g` using `matplotlib`.\n",
    "* Label the x and y axes and give the plot a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef342f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f050a4",
   "metadata": {},
   "source": [
    "Now that you have the hang of it, let's try a few more plots.\n",
    "\n",
    "### âœ… Tasks:\n",
    "* Create a series of scatter plots of `u` vs `g`, `u` vs `r`, `u` vs `i`, and `u` vs `z` in a single figure using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae793a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a45fd",
   "metadata": {},
   "source": [
    "Ok, this is great, but we should notice that there's three classes of objects in the data: `galaxy`, `star`, and `quasar`. We can use this information to color the points in the scatter plot based on their class. You can do this by using the `c` parameter in the `plot()` function to specify the color of the points based on the class column. \n",
    "\n",
    "For example, if you have a dataframe `df` with a column `class`, and variables `x` and `y`, you can create a scatter plot with points colored by class like this:\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "# Plot data on the axes, coloring by class\n",
    "ax.scatter(df['x'], df['y'], c=df['class'].astype('category').cat.codes, cmap='viridis')\n",
    "# Set the x and y axis labels\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "# Set the title of the plot\n",
    "ax.set_title('x vs y colored by class')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### âœ… Tasks:\n",
    "* Create a scatter plot of `u` vs `g` colored by class using `matplotlib`.\n",
    "* Create a series of scatter plots of `u` vs `g`, `u` vs `r`, `u` vs `i`, and `u` vs `z` in a single figure using `matplotlib`, colored by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525bbd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8f990",
   "metadata": {},
   "source": [
    "### 3.2 Using `seaborn`\n",
    "\n",
    "These plots are great, but they are not as visually appealing as we would like. Also, we would additional information about the plots to make them more informative. This is where `seaborn` comes in. `seaborn` is built on top of `matplotlib` and provides a high-level interface for drawing attractive and informative statistical graphics. It simplifies the process of creating complex visualizations.\n",
    "\n",
    "For example, let's create a scatter plot of `u` vs `g` using `seaborn` and color the points by class. For a data frame `df` with columns `x`, `y`, and `class`, you can create a scatter plot like this:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "# Create a scatter plot of x vs y colored by class\n",
    "sns.scatterplot(data=df, x='x', y='y', hue='class')\n",
    "# Set the title of the plot\n",
    "plt.title('x vs y colored by class')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "See how easy that was? `seaborn` takes care of the details for us, such as adding a legend and setting the colors based on the class column.\n",
    "\n",
    "### âœ… Tasks:\n",
    "* Create a scatter plot of `u` vs `g` colored by class using `seaborn`.\n",
    "* Create a series of scatter plots of `u` vs `g`, `u` vs `r`, `u` vs `i`, and `u` vs `z` in a single figure using `seaborn`, colored by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e15815",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4669adfd",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id=\"analysis\"></a>\n",
    "## 4. Data analysis\n",
    "\n",
    "Great! Now that we've learned to import data, to review it for issues, and to visualize it, we can start to do some data analysis. For these tasks, you will need to investigate how to perform the analysis and present the results. You can use the documentation for `pandas`, `matplotlib`, and `seaborn` to help you with this. \n",
    "\n",
    "You are welcome to use any additional libraries that you like.\n",
    "\n",
    "### Research questions\n",
    "\n",
    "1. What is the distribution of the photometric values (`u`, `g`, `r`, `i`, `z`) for each class? That is, how do the photometric values vary for each class of object? **Think histograms, box plots, or violin plots.**\n",
    "2. How do the photometric values (`u`, `g`, `r`, `i`, `z`) linearly correlate with each other for each class? **Think scatter plots; correlation matrices; and lines of best fit.**\n",
    "3. What is the distribution of redshift values for each class? **Think histograms or box plots.**\n",
    "4. How do photometric values (`u`, `g`, `r`, `i`, `z`) vary with redshift for each class? **Think scatter plots with lines of best fit.**\n",
    "\n",
    "### âœ… Tasks:\n",
    "\n",
    "* Work in groups to answer the research questions.\n",
    "* Use the documentation for `pandas`, `matplotlib`, and `seaborn` to help you with the analysis.\n",
    "* Document your analysis in the notebook, including any code you used and the results of your analysis.\n",
    "* Take your time, there's no rush to complete all the tasks. The goal is to learn how to use the tools and to practice data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c4e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e9b8a",
   "metadata": {},
   "source": [
    "---\n",
    "### Additional resources\n",
    "\n",
    "* [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "* [Matplotlib documentation](https://matplotlib.org/stable/contents.html)\n",
    "* [Seaborn documentation](https://seaborn.pydata.org/)\n",
    "\n",
    "#### Websites with examples of data analysis with `pandas`, `matplotlib`, and `seaborn`:\n",
    "\n",
    "* [Pandas Cookbook](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html)\n",
    "* [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html)\n",
    "* [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a08c5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}